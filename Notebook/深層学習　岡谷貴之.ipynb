{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/x-mathjax-config\">\n",
       "MathJax.Hub.Config({\n",
       "  displayAlign: \"left\",\n",
       "  displayIndent: \"2em\"\n",
       "});\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<script type=\"text/x-mathjax-config\">\n",
    "MathJax.Hub.Config({\n",
    "  displayAlign: \"left\",\n",
    "  displayIndent: \"2em\"\n",
    "});\n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 順伝播型ニューラルネットワーク\n",
    "\n",
    "\n",
    "- 活性化関数  \n",
    "    1. シグモイド関数(sigmoid function)\n",
    "        - 入力値の絶対値が大きな値をとると出力が飽和し一定値をとる  \n",
    "        - その間の入力に対して出力が徐々にかつなめらかに変化する\n",
    "        - 生物の神経細胞が持つ性質をモデル化      \n",
    "            - ロジスティックシグモイド関数(logistic sigmoid function)  \n",
    "$$ \\begin{align*} f(u) = \\frac{1}{1 + e^{-u}} \\tag{1} \\end{align*}$$  \n",
    "            - 双曲線正接関数()  \n",
    "$$ f(u) = tanh(u) $$\n",
    "$$ tanh(u) = \\frac{e^u - e^{-u}}{e^u + e^{-u}} \\tag{2}$$\n",
    "<br>\n",
    "    2. 正規化線形関数(retified linear function)\n",
    "        - この関数を持つユニット = ReLU(Rectified Linear Unit) \n",
    "        - 単純で計算量が小さく、上述2関数より高速に学習可能\n",
    "        - シグモイド関数の場合、入力値が極小・極大だとo,1のどちらかに収束してしまう\n",
    "$$ f(u) = max(u, 0) \\tag{3}$$\n",
    "<br>\n",
    "    3. 恒等写像\n",
    "        - 入力がそのまま出力となる関数\n",
    "        - 回帰問題の出力層活性化関数として用いる\n",
    "        - 分類問題の出力層活性化関数はsoftmax関数を用いる\n",
    "$$ f(u) = u \\tag{4}$$\n",
    "<br>\n",
    "    4. ロジスティックシグモイドの近似関数\n",
    "$$ f(u) = \\left\\{ \\begin{array}{ll}\n",
    "                -1 & u < -1 \\\\\n",
    "                u & -1 \\leq u < 1 \\\\\n",
    "                1 & u \\geq 1\n",
    "             \\end{array} \\right. \\tag{4}\n",
    "$$\n",
    "\n",
    "    5. マックスアウト関数  \n",
    "        - この活性化関数を持つユニットはK個の異なるユニットを合わせたような構造を持つ\n",
    "        - K個の一つ一つが異なる重みとバイアスを持ち、それぞれの総入力を$ u_{j1},...,u_{jK} $と別々に計算した後、それらの最大値をユニットの出力とする  \n",
    "        - このユニットを使用したNNはReLUを使用したNNをしのぐ結果を出している\n",
    "        - パラメータ数は普通のK倍となるためそれほど使われるものではない\n",
    "        - CNNの最大プーリングは実質的に同じ計算をしている  \n",
    "$$ \\begin{array}\n",
    "    u_{jk} = \\Sigma_i w_{jik}z_i + b_{jk} & (k = 1,...,K)\\\\\n",
    "    f(u_j) = \\max_{k=1,...,K} u_{jk}\n",
    "   \\end{array} \\tag{5}\n",
    "$$\n",
    "\n",
    "***\n",
    "- 多層ネットワーク\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
