{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple RNN\n",
    "### バイナリ加算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters:0\n",
      "Loss:1.8494238762012876\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 0 1 1 1 0 0]\n",
      "77 + 15 = 0\n",
      "------------\n",
      "iters:100\n",
      "Loss:0.7532851202333684\n",
      "Pred:[1 0 1 1 0 1 0 0]\n",
      "True:[0 1 1 1 0 1 0 0]\n",
      "64 + 52 = 180\n",
      "------------\n",
      "iters:200\n",
      "Loss:0.9485396704615506\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 1 0 1 0 0]\n",
      "123 + 25 = 255\n",
      "------------\n",
      "iters:300\n",
      "Loss:0.8736950800451835\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 1 1 0 1 1 0]\n",
      "63 + 55 = 126\n",
      "------------\n",
      "iters:400\n",
      "Loss:1.064712239456583\n",
      "Pred:[0 0 0 0 1 0 0 0]\n",
      "True:[0 1 1 0 1 0 1 1]\n",
      "4 + 103 = 8\n",
      "------------\n",
      "iters:500\n",
      "Loss:1.1778715171128935\n",
      "Pred:[0 0 0 1 0 0 0 0]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "110 + 16 = 16\n",
      "------------\n",
      "iters:600\n",
      "Loss:0.9774336026195505\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 1 0 0 1 1 1]\n",
      "56 + 111 = 255\n",
      "------------\n",
      "iters:700\n",
      "Loss:0.9630097356171629\n",
      "Pred:[0 1 0 0 1 0 1 1]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "1 + 109 = 75\n",
      "------------\n",
      "iters:800\n",
      "Loss:0.7533808406641302\n",
      "Pred:[1 0 1 0 0 0 1 1]\n",
      "True:[1 0 1 0 0 0 1 1]\n",
      "80 + 83 = 163\n",
      "------------\n",
      "iters:900\n",
      "Loss:1.1792121072945714\n",
      "Pred:[1 1 0 0 1 1 0 1]\n",
      "True:[1 0 0 1 0 0 1 0]\n",
      "103 + 43 = 205\n",
      "------------\n",
      "iters:1000\n",
      "Loss:0.6931537834812389\n",
      "Pred:[0 0 0 1 1 0 0 0]\n",
      "True:[0 0 0 1 0 0 1 0]\n",
      "6 + 12 = 24\n",
      "------------\n",
      "iters:1100\n",
      "Loss:0.8544630020488208\n",
      "Pred:[1 1 1 1 1 0 1 1]\n",
      "True:[0 1 1 1 1 1 0 1]\n",
      "24 + 101 = 251\n",
      "------------\n",
      "iters:1200\n",
      "Loss:0.6341320428142755\n",
      "Pred:[1 1 1 1 1 1 0 1]\n",
      "True:[1 0 1 0 1 1 0 1]\n",
      "90 + 83 = 253\n",
      "------------\n",
      "iters:1300\n",
      "Loss:1.1135258915811492\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 0 0 0 1 1]\n",
      "40 + 91 = 255\n",
      "------------\n",
      "iters:1400\n",
      "Loss:0.6605644840132079\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 1 1 1 1 1]\n",
      "3 + 124 = 125\n",
      "------------\n",
      "iters:1500\n",
      "Loss:0.6426415942090125\n",
      "Pred:[0 0 1 1 1 1 0 1]\n",
      "True:[0 0 1 1 1 1 1 1]\n",
      "26 + 37 = 61\n",
      "------------\n",
      "iters:1600\n",
      "Loss:0.7154732587557023\n",
      "Pred:[1 0 1 0 0 0 0 0]\n",
      "True:[1 1 0 0 0 1 0 0]\n",
      "84 + 112 = 160\n",
      "------------\n",
      "iters:1700\n",
      "Loss:0.9687309893985059\n",
      "Pred:[0 1 0 1 0 1 0 0]\n",
      "True:[0 1 0 0 1 0 0 1]\n",
      "59 + 14 = 84\n",
      "------------\n",
      "iters:1800\n",
      "Loss:0.612203342724819\n",
      "Pred:[1 0 0 0 0 0 0 0]\n",
      "True:[1 1 0 1 1 0 0 0]\n",
      "96 + 120 = 128\n",
      "------------\n",
      "iters:1900\n",
      "Loss:0.7540844837832137\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "66 + 53 = 125\n",
      "------------\n",
      "iters:2000\n",
      "Loss:0.5986245575576372\n",
      "Pred:[0 0 0 1 1 1 1 1]\n",
      "True:[0 0 0 1 0 1 0 0]\n",
      "15 + 5 = 31\n",
      "------------\n",
      "iters:2100\n",
      "Loss:0.6256672149328055\n",
      "Pred:[1 0 0 1 0 0 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "36 + 94 = 146\n",
      "------------\n",
      "iters:2200\n",
      "Loss:0.5754170421208671\n",
      "Pred:[1 1 0 1 1 1 0 0]\n",
      "True:[1 1 0 1 1 0 0 0]\n",
      "106 + 110 = 220\n",
      "------------\n",
      "iters:2300\n",
      "Loss:0.5040575571987604\n",
      "Pred:[0 1 1 1 0 0 1 0]\n",
      "True:[0 1 1 1 0 0 1 0]\n",
      "68 + 46 = 114\n",
      "------------\n",
      "iters:2400\n",
      "Loss:0.2486279740182175\n",
      "Pred:[1 0 1 0 1 1 0 0]\n",
      "True:[1 0 1 0 1 1 0 0]\n",
      "67 + 105 = 172\n",
      "------------\n",
      "iters:2500\n",
      "Loss:1.0839158956883437\n",
      "Pred:[0 1 1 0 0 0 0 0]\n",
      "True:[0 1 0 1 1 1 1 1]\n",
      "75 + 20 = 96\n",
      "------------\n",
      "iters:2600\n",
      "Loss:0.3122315762790968\n",
      "Pred:[0 0 1 1 1 0 0 0]\n",
      "True:[0 0 1 1 1 0 0 0]\n",
      "43 + 13 = 56\n",
      "------------\n",
      "iters:2700\n",
      "Loss:0.29728276650287533\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 0]\n",
      "24 + 112 = 136\n",
      "------------\n",
      "iters:2800\n",
      "Loss:0.28456697287294963\n",
      "Pred:[0 1 1 0 1 0 1 1]\n",
      "True:[0 1 1 0 1 0 1 1]\n",
      "2 + 105 = 107\n",
      "------------\n",
      "iters:2900\n",
      "Loss:0.10871440701508998\n",
      "Pred:[0 1 0 1 1 0 0 0]\n",
      "True:[0 1 0 1 1 0 0 0]\n",
      "68 + 20 = 88\n",
      "------------\n",
      "iters:3000\n",
      "Loss:0.0524035655523436\n",
      "Pred:[0 1 0 1 1 0 1 0]\n",
      "True:[0 1 0 1 1 0 1 0]\n",
      "24 + 66 = 90\n",
      "------------\n",
      "iters:3100\n",
      "Loss:0.07232629026501307\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "98 + 12 = 110\n",
      "------------\n",
      "iters:3200\n",
      "Loss:0.2977578081587776\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 1 1]\n",
      "108 + 23 = 129\n",
      "------------\n",
      "iters:3300\n",
      "Loss:0.13161956883251777\n",
      "Pred:[0 0 1 1 0 1 0 0]\n",
      "True:[0 0 1 1 0 1 0 0]\n",
      "5 + 47 = 52\n",
      "------------\n",
      "iters:3400\n",
      "Loss:0.09326071562187073\n",
      "Pred:[0 0 1 1 1 0 0 1]\n",
      "True:[0 0 1 1 1 0 0 1]\n",
      "13 + 44 = 57\n",
      "------------\n",
      "iters:3500\n",
      "Loss:0.11274063604629364\n",
      "Pred:[0 1 1 1 0 0 1 1]\n",
      "True:[0 1 1 1 0 0 1 1]\n",
      "13 + 102 = 115\n",
      "------------\n",
      "iters:3600\n",
      "Loss:0.03369848527706083\n",
      "Pred:[0 1 1 0 1 0 1 1]\n",
      "True:[0 1 1 0 1 0 1 1]\n",
      "56 + 51 = 107\n",
      "------------\n",
      "iters:3700\n",
      "Loss:0.039091942442638215\n",
      "Pred:[0 1 1 1 1 1 0 0]\n",
      "True:[0 1 1 1 1 1 0 0]\n",
      "105 + 19 = 124\n",
      "------------\n",
      "iters:3800\n",
      "Loss:0.04554012172330455\n",
      "Pred:[0 0 1 1 0 1 0 1]\n",
      "True:[0 0 1 1 0 1 0 1]\n",
      "17 + 36 = 53\n",
      "------------\n",
      "iters:3900\n",
      "Loss:0.040692121738847786\n",
      "Pred:[1 0 1 0 0 1 0 1]\n",
      "True:[1 0 1 0 0 1 0 1]\n",
      "60 + 105 = 165\n",
      "------------\n",
      "iters:4000\n",
      "Loss:0.01731333881568725\n",
      "Pred:[1 0 1 1 0 1 1 0]\n",
      "True:[1 0 1 1 0 1 1 0]\n",
      "101 + 81 = 182\n",
      "------------\n",
      "iters:4100\n",
      "Loss:0.03741214594961982\n",
      "Pred:[0 1 0 1 1 1 1 1]\n",
      "True:[0 1 0 1 1 1 1 1]\n",
      "91 + 4 = 95\n",
      "------------\n",
      "iters:4200\n",
      "Loss:0.01972995974086959\n",
      "Pred:[1 0 0 1 0 0 1 0]\n",
      "True:[1 0 0 1 0 0 1 0]\n",
      "76 + 70 = 146\n",
      "------------\n",
      "iters:4300\n",
      "Loss:0.026744748971927287\n",
      "Pred:[0 1 1 1 1 0 0 1]\n",
      "True:[0 1 1 1 1 0 0 1]\n",
      "68 + 53 = 121\n",
      "------------\n",
      "iters:4400\n",
      "Loss:0.015354411689016209\n",
      "Pred:[1 0 0 0 1 1 1 1]\n",
      "True:[1 0 0 0 1 1 1 1]\n",
      "72 + 71 = 143\n",
      "------------\n",
      "iters:4500\n",
      "Loss:0.02039390272547302\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[0 1 0 0 1 0 0 0]\n",
      "28 + 44 = 72\n",
      "------------\n",
      "iters:4600\n",
      "Loss:0.00919963772688803\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[0 1 0 0 1 0 0 0]\n",
      "36 + 36 = 72\n",
      "------------\n",
      "iters:4700\n",
      "Loss:0.01868209988546776\n",
      "Pred:[1 0 0 0 0 0 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "11 + 119 = 130\n",
      "------------\n",
      "iters:4800\n",
      "Loss:0.01217508334191626\n",
      "Pred:[1 0 1 0 0 0 0 0]\n",
      "True:[1 0 1 0 0 0 0 0]\n",
      "60 + 100 = 160\n",
      "------------\n",
      "iters:4900\n",
      "Loss:0.016985193919594316\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 0]\n",
      "94 + 42 = 136\n",
      "------------\n",
      "iters:5000\n",
      "Loss:0.018762278566904135\n",
      "Pred:[1 1 1 1 1 0 0 1]\n",
      "True:[1 1 1 1 1 0 0 1]\n",
      "124 + 125 = 249\n",
      "------------\n",
      "iters:5100\n",
      "Loss:0.010268234906853642\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 1 1]\n",
      "40 + 39 = 79\n",
      "------------\n",
      "iters:5200\n",
      "Loss:0.015843230828631257\n",
      "Pred:[1 1 0 0 0 1 0 0]\n",
      "True:[1 1 0 0 0 1 0 0]\n",
      "75 + 121 = 196\n",
      "------------\n",
      "iters:5300\n",
      "Loss:0.007737542935739014\n",
      "Pred:[0 1 0 0 0 0 1 1]\n",
      "True:[0 1 0 0 0 0 1 1]\n",
      "66 + 1 = 67\n",
      "------------\n",
      "iters:5400\n",
      "Loss:0.013707182450059313\n",
      "Pred:[0 1 0 0 1 0 1 1]\n",
      "True:[0 1 0 0 1 0 1 1]\n",
      "53 + 22 = 75\n",
      "------------\n",
      "iters:5500\n",
      "Loss:0.008087157794071109\n",
      "Pred:[0 1 1 0 1 1 0 1]\n",
      "True:[0 1 1 0 1 1 0 1]\n",
      "62 + 47 = 109\n",
      "------------\n",
      "iters:5600\n",
      "Loss:0.006325150722628822\n",
      "Pred:[0 1 1 0 0 0 0 1]\n",
      "True:[0 1 1 0 0 0 0 1]\n",
      "56 + 41 = 97\n",
      "------------\n",
      "iters:5700\n",
      "Loss:0.011467514092711335\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "7 + 122 = 129\n",
      "------------\n",
      "iters:5800\n",
      "Loss:0.0066952660682719186\n",
      "Pred:[0 1 1 1 1 0 0 0]\n",
      "True:[0 1 1 1 1 0 0 0]\n",
      "59 + 61 = 120\n",
      "------------\n",
      "iters:5900\n",
      "Loss:0.00450025457256395\n",
      "Pred:[0 1 1 0 1 0 0 1]\n",
      "True:[0 1 1 0 1 0 0 1]\n",
      "100 + 5 = 105\n",
      "------------\n",
      "iters:6000\n",
      "Loss:0.0081806756107527\n",
      "Pred:[1 0 0 0 0 1 0 1]\n",
      "True:[1 0 0 0 0 1 0 1]\n",
      "119 + 14 = 133\n",
      "------------\n",
      "iters:6100\n",
      "Loss:0.005110754483723201\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "2 + 79 = 81\n",
      "------------\n",
      "iters:6200\n",
      "Loss:0.006227354868507507\n",
      "Pred:[0 1 0 1 0 1 0 1]\n",
      "True:[0 1 0 1 0 1 0 1]\n",
      "25 + 60 = 85\n",
      "------------\n",
      "iters:6300\n",
      "Loss:0.004124719708139706\n",
      "Pred:[0 1 0 0 1 1 0 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "64 + 13 = 77\n",
      "------------\n",
      "iters:6400\n",
      "Loss:0.005130762942247029\n",
      "Pred:[1 0 1 0 1 0 1 1]\n",
      "True:[1 0 1 0 1 0 1 1]\n",
      "104 + 67 = 171\n",
      "------------\n",
      "iters:6500\n",
      "Loss:0.005579082372172826\n",
      "Pred:[1 0 0 0 0 1 0 1]\n",
      "True:[1 0 0 0 0 1 0 1]\n",
      "53 + 80 = 133\n",
      "------------\n",
      "iters:6600\n",
      "Loss:0.006130504996138167\n",
      "Pred:[1 1 0 0 1 1 0 1]\n",
      "True:[1 1 0 0 1 1 0 1]\n",
      "123 + 82 = 205\n",
      "------------\n",
      "iters:6700\n",
      "Loss:0.0027700414827421744\n",
      "Pred:[0 0 1 1 0 1 1 0]\n",
      "True:[0 0 1 1 0 1 1 0]\n",
      "11 + 43 = 54\n",
      "------------\n",
      "iters:6800\n",
      "Loss:0.003101085107489419\n",
      "Pred:[1 1 1 0 0 1 1 0]\n",
      "True:[1 1 1 0 0 1 1 0]\n",
      "111 + 119 = 230\n",
      "------------\n",
      "iters:6900\n",
      "Loss:0.0014672177760657005\n",
      "Pred:[0 1 0 1 0 1 1 0]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "53 + 33 = 86\n",
      "------------\n",
      "iters:7000\n",
      "Loss:0.005481462662920502\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "71 + 58 = 129\n",
      "------------\n",
      "iters:7100\n",
      "Loss:0.0028069666240834916\n",
      "Pred:[1 0 1 0 0 0 1 0]\n",
      "True:[1 0 1 0 0 0 1 0]\n",
      "63 + 99 = 162\n",
      "------------\n",
      "iters:7200\n",
      "Loss:0.003873196518374343\n",
      "Pred:[0 1 0 1 1 1 1 1]\n",
      "True:[0 1 0 1 1 1 1 1]\n",
      "10 + 85 = 95\n",
      "------------\n",
      "iters:7300\n",
      "Loss:0.0044125690571802986\n",
      "Pred:[0 1 1 0 1 1 1 1]\n",
      "True:[0 1 1 0 1 1 1 1]\n",
      "53 + 58 = 111\n",
      "------------\n",
      "iters:7400\n",
      "Loss:0.0029489860519032896\n",
      "Pred:[1 1 1 0 0 1 0 0]\n",
      "True:[1 1 1 0 0 1 0 0]\n",
      "103 + 125 = 228\n",
      "------------\n",
      "iters:7500\n",
      "Loss:0.0033539163768789688\n",
      "Pred:[0 0 0 1 0 0 1 1]\n",
      "True:[0 0 0 1 0 0 1 1]\n",
      "14 + 5 = 19\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters:7600\n",
      "Loss:0.0036761262671080788\n",
      "Pred:[1 1 0 1 1 0 1 1]\n",
      "True:[1 1 0 1 1 0 1 1]\n",
      "121 + 98 = 219\n",
      "------------\n",
      "iters:7700\n",
      "Loss:0.0034175917804456562\n",
      "Pred:[0 1 1 1 0 0 1 0]\n",
      "True:[0 1 1 1 0 0 1 0]\n",
      "4 + 110 = 114\n",
      "------------\n",
      "iters:7800\n",
      "Loss:0.0009196490973370521\n",
      "Pred:[0 0 1 1 0 1 1 0]\n",
      "True:[0 0 1 1 0 1 1 0]\n",
      "33 + 21 = 54\n",
      "------------\n",
      "iters:7900\n",
      "Loss:0.0028794106836814133\n",
      "Pred:[1 0 0 1 1 1 0 0]\n",
      "True:[1 0 0 1 1 1 0 0]\n",
      "116 + 40 = 156\n",
      "------------\n",
      "iters:8000\n",
      "Loss:0.003053944515117062\n",
      "Pred:[1 0 1 1 0 1 0 1]\n",
      "True:[1 0 1 1 0 1 0 1]\n",
      "59 + 122 = 181\n",
      "------------\n",
      "iters:8100\n",
      "Loss:0.0018666758677501596\n",
      "Pred:[1 0 0 1 0 0 0 0]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "103 + 41 = 144\n",
      "------------\n",
      "iters:8200\n",
      "Loss:0.0029136803071384953\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[0 1 1 0 1 1 0 0]\n",
      "18 + 90 = 108\n",
      "------------\n",
      "iters:8300\n",
      "Loss:0.0027775854188630453\n",
      "Pred:[1 0 1 0 1 0 0 1]\n",
      "True:[1 0 1 0 1 0 0 1]\n",
      "111 + 58 = 169\n",
      "------------\n",
      "iters:8400\n",
      "Loss:0.0015157576284057874\n",
      "Pred:[0 1 0 1 0 1 1 0]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "15 + 71 = 86\n",
      "------------\n",
      "iters:8500\n",
      "Loss:0.0025418049915319867\n",
      "Pred:[0 1 0 1 1 0 0 1]\n",
      "True:[0 1 0 1 1 0 0 1]\n",
      "25 + 64 = 89\n",
      "------------\n",
      "iters:8600\n",
      "Loss:0.002349133502509248\n",
      "Pred:[0 1 0 1 0 1 0 1]\n",
      "True:[0 1 0 1 0 1 0 1]\n",
      "55 + 30 = 85\n",
      "------------\n",
      "iters:8700\n",
      "Loss:0.002328421759515953\n",
      "Pred:[1 0 0 0 0 0 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "62 + 68 = 130\n",
      "------------\n",
      "iters:8800\n",
      "Loss:0.0008539166040702344\n",
      "Pred:[0 1 1 0 1 0 0 0]\n",
      "True:[0 1 1 0 1 0 0 0]\n",
      "5 + 99 = 104\n",
      "------------\n",
      "iters:8900\n",
      "Loss:0.002608826079154743\n",
      "Pred:[0 0 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 1 1 1 1]\n",
      "9 + 54 = 63\n",
      "------------\n",
      "iters:9000\n",
      "Loss:0.000942056313613669\n",
      "Pred:[0 0 1 1 0 0 1 0]\n",
      "True:[0 0 1 1 0 0 1 0]\n",
      "31 + 19 = 50\n",
      "------------\n",
      "iters:9100\n",
      "Loss:0.002125441306274044\n",
      "Pred:[1 0 0 0 0 0 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "30 + 100 = 130\n",
      "------------\n",
      "iters:9200\n",
      "Loss:0.001713607682314764\n",
      "Pred:[0 1 0 0 1 1 1 0]\n",
      "True:[0 1 0 0 1 1 1 0]\n",
      "10 + 68 = 78\n",
      "------------\n",
      "iters:9300\n",
      "Loss:0.001889343593283551\n",
      "Pred:[0 1 1 1 0 1 1 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "110 + 9 = 119\n",
      "------------\n",
      "iters:9400\n",
      "Loss:0.0008656298072500617\n",
      "Pred:[1 0 0 1 1 1 1 0]\n",
      "True:[1 0 0 1 1 1 1 0]\n",
      "83 + 75 = 158\n",
      "------------\n",
      "iters:9500\n",
      "Loss:0.0014416470815896702\n",
      "Pred:[1 0 1 0 1 1 1 0]\n",
      "True:[1 0 1 0 1 1 1 0]\n",
      "68 + 106 = 174\n",
      "------------\n",
      "iters:9600\n",
      "Loss:0.0013788097715938306\n",
      "Pred:[0 1 1 1 1 0 1 0]\n",
      "True:[0 1 1 1 1 0 1 0]\n",
      "104 + 18 = 122\n",
      "------------\n",
      "iters:9700\n",
      "Loss:0.0020750234296428166\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 1 1 1 0 1]\n",
      "107 + 18 = 125\n",
      "------------\n",
      "iters:9800\n",
      "Loss:0.0018340022038776313\n",
      "Pred:[0 1 1 0 1 1 0 1]\n",
      "True:[0 1 1 0 1 1 0 1]\n",
      "27 + 82 = 109\n",
      "------------\n",
      "iters:9900\n",
      "Loss:0.0018359955700988013\n",
      "Pred:[1 0 1 0 0 1 1 1]\n",
      "True:[1 0 1 0 0 1 1 1]\n",
      "124 + 43 = 167\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "from common import functions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tanh導関数\n",
    "# def d_tanh(x):\n",
    "#    return 1 / (np.cosh(x) ** 2)\n",
    "\n",
    "# データを用意\n",
    "# 2進数の桁数\n",
    "binary_dim = 8\n",
    "# 最大値 + 1\n",
    "largest_number = pow(2, binary_dim)\n",
    "# largest_numberまで2進数を用意\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "\n",
    "input_layer_size = 2\n",
    "hidden_layer_size = 16\n",
    "output_layer_size = 1\n",
    "\n",
    "weight_init_std = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "iters_num = 10000\n",
    "plot_interval = 100\n",
    "\n",
    "# ウェイト初期化 (バイアスは簡単のため省略)\n",
    "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
    "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
    "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
    "\n",
    "# Xavier\n",
    "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
    "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
    "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
    "\n",
    "# He\n",
    "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
    "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
    "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
    "\n",
    "\n",
    "# 勾配\n",
    "W_in_grad = np.zeros_like(W_in)\n",
    "W_out_grad = np.zeros_like(W_out)\n",
    "W_grad = np.zeros_like(W)\n",
    "\n",
    "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "y = np.zeros((output_layer_size, binary_dim))\n",
    "\n",
    "delta_out = np.zeros((output_layer_size, binary_dim))\n",
    "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    # A, B初期化 (a + b = d)\n",
    "    a_int = np.random.randint(largest_number/2)\n",
    "    a_bin = binary[a_int] # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2)\n",
    "    b_bin = binary[b_int] # binary encoding\n",
    "    \n",
    "    # 正解データ\n",
    "    d_int = a_int + b_int\n",
    "    d_bin = binary[d_int]\n",
    "    \n",
    "    # 出力バイナリ\n",
    "    out_bin = np.zeros_like(d_bin)\n",
    "    \n",
    "    # 時系列全体の誤差\n",
    "    all_loss = 0    \n",
    "    \n",
    "    # 時系列ループ\n",
    "    for t in range(binary_dim):\n",
    "        # 入力値\n",
    "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
    "        # 時刻tにおける正解データ\n",
    "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
    "        \n",
    "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
    "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
    "#        z[:,t+1] = functions.tanh(u[:,t+1])\n",
    "#        z[:,t+1] = functions.relu(u[:,t+1])\n",
    "\n",
    "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
    "\n",
    "\n",
    "        #誤差\n",
    "        loss = functions.mean_squared_error(dd, y[:,t])\n",
    "        \n",
    "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
    "        \n",
    "        all_loss += loss\n",
    "\n",
    "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
    "    \n",
    "    \n",
    "    for t in range(binary_dim)[::-1]:\n",
    "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
    "\n",
    "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
    "#        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
    "#        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])\n",
    "\n",
    "        \n",
    "        # 勾配更新\n",
    "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
    "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
    "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
    "    \n",
    "    # 勾配適用\n",
    "    W_in -= learning_rate * W_in_grad\n",
    "    W_out -= learning_rate * W_out_grad\n",
    "    W -= learning_rate * W_grad\n",
    "    \n",
    "    W_in_grad *= 0\n",
    "    W_out_grad *= 0\n",
    "    W_grad *= 0\n",
    "    \n",
    "\n",
    "    if(i % plot_interval == 0):\n",
    "        all_losses.append(all_loss)        \n",
    "        print(\"iters:\" + str(i))\n",
    "        print(\"Loss:\" + str(all_loss))\n",
    "        print(\"Pred:\" + str(out_bin))\n",
    "        print(\"True:\" + str(d_bin))\n",
    "        out_int = 0\n",
    "        for index,x in enumerate(reversed(out_bin)):\n",
    "            out_int += x * pow(2, index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
    "        print(\"------------\")\n",
    "\n",
    "lists = range(0, iters_num, plot_interval)\n",
    "plt.plot(lists, all_losses, label=\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "## [try] weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう\n",
    "\n",
    "\n",
    "## [try] 重みの初期化方法を変更してみよう\n",
    "Xavier, He\n",
    "\n",
    "## [try] 中間層の活性化関数を変更してみよう\n",
    "ReLU(勾配爆発を確認しよう)<br>\n",
    "tanh(numpyにtanhが用意されている。導関数をd_tanhとして作成しよう)\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
